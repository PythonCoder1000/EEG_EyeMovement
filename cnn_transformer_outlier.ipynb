{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Install dependencies (Colab) ---\n",
        "!pip install -q torch torchvision torchaudio scikit-learn matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5DbAoU8FiS7",
        "outputId": "81e9b93f-4b4f-4c03-f3c4-2687e4fc1439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Imports ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OtkiFlN4Fhy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mount Google Drive ---\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Fk4EI27HFhw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba213c2b-d7a1-427f-857e-609a8b3953c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Constants for screen setup ---\n",
        "SCREEN_WIDTH_PX = 800\n",
        "SCREEN_HEIGHT_PX = 600\n",
        "SCREEN_WIDTH_MM = 518\n",
        "SCREEN_HEIGHT_MM = 324\n",
        "VIEWING_DISTANCE_MM = 680"
      ],
      "metadata": {
        "id": "2jcaFFmjFhuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Positional Encoding ---\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=1200):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "# --- Patch Embedding via Conv ---\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels=1, emb_size=256):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(64, emb_size, kernel_size=3, stride=2, padding=1),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.proj(x)\n",
        "        B, E, H, W = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "# --- Transformer Encoder Block ---\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, emb_size=256, heads=4, ff_dim=512, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.attn = nn.MultiheadAttention(emb_size, heads, dropout=dropout, batch_first=True)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(emb_size, ff_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(ff_dim, emb_size)\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(emb_size, eps=1e-5)\n",
        "        self.norm2 = nn.LayerNorm(emb_size, eps=1e-5)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out, _ = self.attn(x, x, x)\n",
        "        x = self.norm1(x + self.drop(attn_out))\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.norm2(x + self.drop(ff_out))\n",
        "        return x\n",
        "\n",
        "# --- Full Model with Attention Pooling ---\n",
        "class EEGTransformerRegressor(nn.Module):\n",
        "    def __init__(self, emb_size=256, num_layers=4):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbedding(1, emb_size)\n",
        "        self.pos_encoder = PositionalEncoding(emb_size)\n",
        "        self.transformer = nn.Sequential(*[\n",
        "            TransformerBlock(emb_size) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.attn_pool = nn.MultiheadAttention(emb_size, num_heads=4, batch_first=True)\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.LayerNorm(emb_size, eps=1e-5),\n",
        "            nn.Linear(emb_size, 64),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer(x)\n",
        "        pooled, _ = self.attn_pool(x, x, x)\n",
        "        return self.regressor(pooled[:, 0])\n",
        "\n",
        "# --- Dataset ---\n",
        "class EEGNPZDataset(Dataset):\n",
        "    def __init__(self, file_paths, file_fraction=0.75):\n",
        "        self.samples = []\n",
        "        for path in file_paths:\n",
        "            data = np.load(path)\n",
        "            eeg = data['EEG']\n",
        "            labels = data['labels'][:, -2:]\n",
        "            n = int(len(eeg) * file_fraction)\n",
        "            for x, y in zip(eeg[:n], labels[:n]):\n",
        "                if not np.isnan(x).any() and not np.isnan(y).any():\n",
        "                    deg_x, deg_y = pixels_to_degrees(y[0], y[1])\n",
        "                    if abs(deg_x) < 30 and abs(deg_y) < 30:\n",
        "                        x = (x - np.mean(x)) / (np.std(x) + 1e-6)\n",
        "                        self.samples.append((x, y))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.samples[idx]\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "RV_4McHmFhrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixels_to_degrees(x_px, y_px):\n",
        "    x_mm = (x_px - SCREEN_WIDTH_PX / 2) * (SCREEN_WIDTH_MM / SCREEN_WIDTH_PX)\n",
        "    y_mm = (y_px - SCREEN_HEIGHT_PX / 2) * (SCREEN_HEIGHT_MM / SCREEN_HEIGHT_PX)\n",
        "    angle_x = np.degrees(np.arctan2(x_mm, VIEWING_DISTANCE_MM))\n",
        "    angle_y = np.degrees(np.arctan2(y_mm, VIEWING_DISTANCE_MM))\n",
        "    return angle_x, angle_y\n",
        "\n",
        "# --- RMSE in degrees of visual angle ---\n",
        "def rmse_degrees(preds, targets):\n",
        "    preds_deg = np.array([pixels_to_degrees(x, y) for x, y in preds])\n",
        "    targets_deg = np.array([pixels_to_degrees(x, y) for x, y in targets])\n",
        "    return np.sqrt(np.mean((preds_deg - targets_deg) ** 2))\n",
        "def pixels_to_mm(x_px, y_px):\n",
        "    x_mm = (x_px - SCREEN_WIDTH_PX / 2) * (SCREEN_WIDTH_MM / SCREEN_WIDTH_PX)\n",
        "    y_mm = (y_px - SCREEN_HEIGHT_PX / 2) * (SCREEN_HEIGHT_MM / SCREEN_HEIGHT_PX)\n",
        "    return x_mm, y_mm\n",
        "def rmse_mm(preds, targets):\n",
        "    preds_mm = np.array([pixels_to_mm(x, y) for x, y in preds])\n",
        "    targets_mm = np.array([pixels_to_mm(x, y) for x, y in targets])\n",
        "    return np.sqrt(np.mean((preds_mm - targets_mm) ** 2))"
      ],
      "metadata": {
        "id": "7lpIwHb6Fosw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlV5971sDQ7S"
      },
      "outputs": [],
      "source": [
        "# --- Training Loop ---\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, save_dir, patience=5):\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    best_rmse = float('inf')\n",
        "    train_losses = []\n",
        "    val_rmses = []\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
        "            inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                outputs = model(inputs)\n",
        "\n",
        "            if torch.isnan(outputs).any():\n",
        "                print(f\"❌ NaNs detected in outputs at batch {batch_idx}\")\n",
        "                del inputs, targets, outputs\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            if not torch.isfinite(loss).all():\n",
        "                print(f\"⚠️ Skipping batch {batch_idx} with non-finite loss: {loss.item()}\")\n",
        "                del inputs, targets, outputs, loss\n",
        "                torch.cuda.empty_cache()\n",
        "                continue\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            del inputs, targets, outputs, loss\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        preds, gts = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                preds.append(outputs.cpu().numpy())\n",
        "                gts.append(targets.cpu().numpy())\n",
        "\n",
        "        preds = np.concatenate(preds)\n",
        "        gts = np.concatenate(gts)\n",
        "        rmse = np.sqrt(mean_squared_error(gts, preds))\n",
        "        val_rmses.append(rmse)\n",
        "        rmse_deg = rmse_degrees(preds, gts)\n",
        "        rmse_mm_val = rmse_mm(preds, gts)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), os.path.join(save_dir, \"best_model.pt\"))\n",
        "            print(\"✅ Saved new best model.\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"⏳ No improvement. Patience: {patience_counter}/{patience}\")\n",
        "            if patience_counter >= patience:\n",
        "                print(\"🛑 Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val RMSE: {rmse:.2f}px | {rmse_deg:.2f}° | {rmse_mm_val:.2f}mm\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(val_rmses, label='Validation RMSE (px)')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss / RMSE')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.savefig(os.path.join(save_dir, 'loss_plot.png'))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/data\"\n",
        "files = [\n",
        "    \"Direction_task_with_dots_synchronised_max.npz\",\n",
        "    \"Direction_task_with_dots_synchronised_min.npz\",\n",
        "    \"Direction_task_with_processing_speed_synchronised_max.npz\",\n",
        "    \"Direction_task_with_processing_speed_synchronised_min.npz\",\n",
        "]\n",
        "file_paths = [os.path.join(data_dir, f) for f in files]\n",
        "\n",
        "dataset = EEGNPZDataset(file_paths)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)"
      ],
      "metadata": {
        "id": "8_MeR2I6F4c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = EEGTransformerRegressor().to(device)\n",
        "\n",
        "    criterion = nn.SmoothL1Loss(beta=10.0)  # beta controls transition to L1\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5)\n",
        "\n",
        "    save_dir = \"/content/drive/MyDrive/cnn_transformer/outliers/Try1\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=100, device=device, save_dir=save_dir, patience=5)"
      ],
      "metadata": {
        "id": "Kwl_0IujFxDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d617c016-4992-45e7-dc50-d032af9ea949"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 925/925 [05:49<00:00,  2.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [1/100] | Train Loss: 89.4318 | Val RMSE: 131.75px | 7.03° | 85.30mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [2/100] | Train Loss: 68.9017 | Val RMSE: 126.83px | 6.76° | 82.12mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [3/100] | Train Loss: 65.2511 | Val RMSE: 115.15px | 6.14° | 74.55mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [4/100] | Train Loss: 57.2298 | Val RMSE: 107.94px | 5.77° | 69.89mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [5/100] | Train Loss: 50.2155 | Val RMSE: 103.03px | 5.50° | 66.71mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [6/100] | Train Loss: 47.1611 | Val RMSE: 91.07px | 4.85° | 58.96mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [7/100] | Train Loss: 42.7516 | Val RMSE: 88.13px | 4.70° | 57.06mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [8/100] | Train Loss: 38.9840 | Val RMSE: 84.46px | 4.50° | 54.69mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [9/100] | Train Loss: 37.1292 | Val RMSE: 81.36px | 4.33° | 52.68mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [10/100] | Train Loss: 36.2607 | Val RMSE: 81.78px | 4.36° | 52.95mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 2/5\n",
            "Epoch [11/100] | Train Loss: 37.1679 | Val RMSE: 81.60px | 4.34° | 52.83mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 3/5\n",
            "Epoch [12/100] | Train Loss: 36.3218 | Val RMSE: 88.09px | 4.69° | 57.04mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [13/100] | Train Loss: 36.0122 | Val RMSE: 80.69px | 4.30° | 52.24mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [14/100] | Train Loss: 34.4102 | Val RMSE: 78.83px | 4.20° | 51.04mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [15/100] | Train Loss: 33.2366 | Val RMSE: 78.98px | 4.21° | 51.14mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [16/100] | Train Loss: 34.6044 | Val RMSE: 78.73px | 4.19° | 50.97mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [17/100] | Train Loss: 34.0916 | Val RMSE: 79.70px | 4.25° | 51.60mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [18/100] | Train Loss: 33.0014 | Val RMSE: 76.35px | 4.07° | 49.44mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [19/100] | Train Loss: 31.6014 | Val RMSE: 77.51px | 4.13° | 50.18mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [20/100] | Train Loss: 30.7279 | Val RMSE: 75.78px | 4.04° | 49.06mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [21/100] | Train Loss: 33.9997 | Val RMSE: 76.13px | 4.05° | 49.29mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 2/5\n",
            "Epoch [22/100] | Train Loss: 32.1897 | Val RMSE: 75.78px | 4.03° | 49.06mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [23/100] | Train Loss: 30.0959 | Val RMSE: 74.59px | 3.97° | 48.29mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [24/100] | Train Loss: 28.9778 | Val RMSE: 74.97px | 3.99° | 48.54mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [25/100] | Train Loss: 28.3042 | Val RMSE: 73.82px | 3.93° | 47.79mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [26/100] | Train Loss: 30.5782 | Val RMSE: 77.46px | 4.13° | 50.15mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 2/5\n",
            "Epoch [27/100] | Train Loss: 29.0073 | Val RMSE: 75.67px | 4.03° | 48.99mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 3/5\n",
            "Epoch [28/100] | Train Loss: 27.9978 | Val RMSE: 74.09px | 3.95° | 47.97mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [29/100] | Train Loss: 26.7288 | Val RMSE: 72.83px | 3.88° | 47.15mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [30/100] | Train Loss: 26.0476 | Val RMSE: 72.48px | 3.86° | 46.93mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [31/100] | Train Loss: 28.5942 | Val RMSE: 74.28px | 3.95° | 48.09mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 2/5\n",
            "Epoch [32/100] | Train Loss: 27.9446 | Val RMSE: 73.23px | 3.90° | 47.41mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 3/5\n",
            "Epoch [33/100] | Train Loss: 26.5660 | Val RMSE: 73.40px | 3.91° | 47.53mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 4/5\n",
            "Epoch [34/100] | Train Loss: 25.0953 | Val RMSE: 73.09px | 3.89° | 47.32mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [35/100] | Train Loss: 23.8702 | Val RMSE: 72.18px | 3.84° | 46.73mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [36/100] | Train Loss: 26.4805 | Val RMSE: 74.32px | 3.96° | 48.12mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 2/5\n",
            "Epoch [37/100] | Train Loss: 27.4224 | Val RMSE: 72.63px | 3.87° | 47.03mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 3/5\n",
            "Epoch [38/100] | Train Loss: 25.1186 | Val RMSE: 72.50px | 3.86° | 46.94mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [39/100] | Train Loss: 22.9626 | Val RMSE: 72.15px | 3.84° | 46.71mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [40/100] | Train Loss: 22.1687 | Val RMSE: 71.70px | 3.82° | 46.42mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [41/100] | Train Loss: 25.0521 | Val RMSE: 72.43px | 3.86° | 46.89mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved new best model.\n",
            "Epoch [42/100] | Train Loss: 23.2630 | Val RMSE: 71.25px | 3.79° | 46.13mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 1/5\n",
            "Epoch [43/100] | Train Loss: 22.2588 | Val RMSE: 72.53px | 3.86° | 46.96mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 2/5\n",
            "Epoch [44/100] | Train Loss: 20.9991 | Val RMSE: 72.21px | 3.84° | 46.76mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 3/5\n",
            "Epoch [45/100] | Train Loss: 20.2004 | Val RMSE: 71.77px | 3.82° | 46.47mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 4/5\n",
            "Epoch [46/100] | Train Loss: 23.0403 | Val RMSE: 73.38px | 3.91° | 47.51mm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47: 100%|██████████| 925/925 [05:49<00:00,  2.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ No improvement. Patience: 5/5\n",
            "🛑 Early stopping triggered.\n"
          ]
        }
      ]
    }
  ]
}